{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADM_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "phLVUhTBcCJ2"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k4jQIPTccQA"
      },
      "source": [
        "\n",
        "1.1 Get the list of animes\n",
        "\n",
        "With the for loop,we get the url of all the pages (50 per page except the last one which has less, 383 pages)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyke871Pce4T",
        "outputId": "ca749722-e3c3-433b-a0df-92b229ec3435"
      },
      "source": [
        "urls=[]\n",
        "for i in tqdm(range(0,20000,50)):\n",
        "  url='https://myanimelist.net/topanime.php?limit='+str(i)\n",
        "  \n",
        "  soup= BeautifulSoup(requests.get(url).text,'html.parser')\n",
        "\n",
        "  for tag in soup.find_all('tr'):\n",
        "    links=tag.find_all('a')\n",
        "    for l in links:\n",
        "      if type(l.get('id'))== str and len(l.contents[0]) >1:\n",
        "        urls.append(l.get('href'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [03:22<00:00,  1.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPENB_rjckdf",
        "outputId": "0290fa56-a6e3-4093-9c82-a2b49689ae5e"
      },
      "source": [
        "len(urls)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19153"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcYZ-d5clZZ"
      },
      "source": [
        "here we saved urls as .txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JW66AFdcoVR"
      },
      "source": [
        "with open('urls.txt', 'w', encoding='utf-8') as f: \n",
        "    for line in urls:\n",
        "        f.write(line)\n",
        "        f.write('\\n')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8hXeEnc0y5"
      },
      "source": [
        "1.2 Crawl animes\n",
        "\n",
        "Create the folders. Put all of them under \"pages\". Each folder has a name that refers to the number of the page from which the links it contains come from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15oC_fAnfyfL"
      },
      "source": [
        "Here we used MyDriver to collect anime folders by pages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxXw6I1QMW8h",
        "outputId": "f97ebb41-6392-48c1-d171-579f5203615f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "qamFnit6cypp",
        "outputId": "db26fece-4b6e-47d5-934d-968abdee7e0b"
      },
      "source": [
        "import os\n",
        "for page in tqdm(range(1, 384)):\n",
        "    folder = \"page\"+str(page)\n",
        "    path = \"/content/drive/MyDrive/Anime_folder\"+folder\n",
        "    os.mkdir(path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/383 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8a8ade5f0812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"page\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Anime_folder\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/Anime_folderpage1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77rxGt7KdAY9"
      },
      "source": [
        "!rm -rf pages\n",
        "   #to delete folders that are not needed."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obgo8WdIdHBx"
      },
      "source": [
        "Try for the first 150:ok. Try to collect them in group of 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNvwpC7KdQE2",
        "outputId": "f821dc21-734d-47c5-92d2-e4ddd34ad842"
      },
      "source": [
        "for page in tqdm(range(4, 8)):  # page 1 --> 383\n",
        "    folder = \"/content/drive/MyDrive/Anime_folderpage\"+str(page+1)\n",
        "    update_page = 50*page\n",
        "    for i in range(0,50):   # 1 -> 50\n",
        "        url = f'{urls[update_page+i]}'\n",
        "        response = requests.get(url)   \n",
        "        filename = r\"\"+folder+\"/anime_\"+str(update_page+i+1)+\".html\"\n",
        "        with open(filename,'w', encoding='utf-8') as f:\n",
        "            f.write(response.text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [02:52<00:00, 43.11s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnLMDl3_dS2h"
      },
      "source": [
        "\n",
        "1.3 Parsing downloaded pages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h0VXIX9gPBq"
      },
      "source": [
        "Here is created functions in order to get needed information, like the title or the number of series and so on. To do that we send the url of the anime to the function and we extract needed info.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDkKijVzdWuG"
      },
      "source": [
        "def AnimeTitle(html):\n",
        "  with open(html,'r') as f:\n",
        "    soup= BeautifulSoup(f)\n",
        "    animeTitle=soup.find(\"h1\", attrs = {\"class\": \"title-name h1_bold_none\"}).string\n",
        "    return(animeTitle)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikjdKyN5XRYV"
      },
      "source": [
        "def animeScore(html):\n",
        "  with open(html,'r') as f:\n",
        "    soup= BeautifulSoup(f)\n",
        "    for i in range(10):\n",
        "      score=soup.find_all('div' ,attrs = {\"class\": \"score-label score-\"+str(i)})\n",
        "      for j in score:\n",
        "        return float(j.text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xkzIs1bXeub"
      },
      "source": [
        "def AnimeRank(html):\n",
        "  with open(html,'r') as f:\n",
        "    soup= BeautifulSoup(f)\n",
        "    rank=int(str(soup.find(class_=\"numbers ranked\").text).split('#')[-1])  \n",
        "    return(rank)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6X0hJhiXpQH"
      },
      "source": [
        "def animeNumberofepisode(html_string):\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A=soup.find(text=re.compile('Episodes:')).parent.parent.text.split()[-1]      \n",
        "    print(A)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9huVo6MtXwCo"
      },
      "source": [
        "def AnimePopularity(html):\n",
        "  with open(html,'r') as f:\n",
        "    soup= BeautifulSoup(f)\n",
        "    rank=int(str(soup.find(class_=\"numbers popularity\").text).split('#')[-1])  \n",
        "    return(rank)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G39v1S9JX0im"
      },
      "source": [
        "def animeDescription(html_string): \n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    A=soup.find(itemprop=\"description\")\n",
        "    return A.get_text()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tJkOA5lX99w"
      },
      "source": [
        "def animeUsers(html_string): \n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    A=soup.find(itemprop=\"ratingCount\")\n",
        "    return int(A.get_text())"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w7cjv2eX-ur"
      },
      "source": [
        "def animeType(html_string):\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A=soup.find(text=re.compile('Type:')).parent.parent.text.split()[-1]      \n",
        "    print(A)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yzjBHOAQdYqW",
        "outputId": "7212a818-6ad6-46d9-dfe3-8dfb3e42e1f4"
      },
      "source": [
        "AnimeTitle('/content/drive/MyDrive/Anime_folderpage1/anime_10.html')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Gintama: The Final'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRARLmBKda72",
        "outputId": "d6b24933-c62a-4e75-dace-876b833837a1"
      },
      "source": [
        "animeScore('/content/drive/MyDrive/Anime_folderpage1/anime_13.html')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.97"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQdc55DKdhIm",
        "outputId": "d36ccba7-718e-44c1-f4f7-c15e3a1c4f01"
      },
      "source": [
        "AnimeRank('/content/drive/MyDrive/Anime_folderpage1/anime_13.html')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP2nhzYydjT3"
      },
      "source": [
        "import re"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZd8AYFUdmzY",
        "outputId": "88f76cae-91d6-44f5-e03c-de04c0d5d718"
      },
      "source": [
        "animeNumberofepisode('/content/drive/MyDrive/Anime_folderpage1/anime_1.html')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEU2lgAQdqWK",
        "outputId": "25c80f49-b1e8-4387-decd-3a64007807fc"
      },
      "source": [
        "AnimePopularity('/content/drive/MyDrive/Anime_folderpage1/anime_13.html')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ebntLTGadwBM",
        "outputId": "0c21db42-df0b-4446-9abd-90740a9984d0"
      },
      "source": [
        "animeDescription('/content/drive/MyDrive/Anime_folderpage1/anime_10.html')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'New Gintama movie.'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s84ZGFBcd0OV",
        "outputId": "0f167bf4-3449-4a7f-be8c-96815b667083"
      },
      "source": [
        "animeUsers('/content/drive/MyDrive/Anime_folderpage1/anime_13.html')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1227199"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j588B0p5d19h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d55a257-6ba5-4dcf-ea2c-e84ea38857ac"
      },
      "source": [
        "animeType('/content/drive/MyDrive/Anime_folderpage1/anime_11.html')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFaYEYGd5h_"
      },
      "source": [
        "def fai_date(a: list):\n",
        "    \n",
        "    string = ''\n",
        "    for i in a:\n",
        "        string += i\n",
        "        if i != a[-1]:\n",
        "            string += ' '\n",
        "    string = string.replace(',', '')\n",
        "    date = datetime.strptime(string, '%b %d %Y')\n",
        "    return date"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC390Eyxd7Vd"
      },
      "source": [
        "def animeRelDate(html_string):\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A= fai_date(soup.find(text=re.compile('Aired:'), class_=\"dark_text\").parent.text.split()[1:4]  )   \n",
        "    print(A)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlXgPtdCeAu6"
      },
      "source": [
        "def animeEndDate(html_string):\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A= fai_date(soup.find(text=re.compile('Aired:'), class_=\"dark_text\").parent.text.split()[5:8]   )  \n",
        "    print(A)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsGyJuTXeDPj"
      },
      "source": [
        "def animeRelated(html_string):  \n",
        "  animeRelated = []\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    related = soup.find_all(\"table\", {\"class\":\"anime_detail_related_anime\"})\n",
        "    for i in related:\n",
        "      links = i.find_all('a')\n",
        "      for link in links:        \n",
        "          animeRelated.append(f'{link.contents[0]}')\n",
        "\n",
        "  return animeRelated"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVrVEeKieFCa",
        "outputId": "64d34b8c-e96d-466e-db74-9543eb74077e"
      },
      "source": [
        "animeRelated('/content/drive/MyDrive/Anime_folderpage1/anime_11.html')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gintama', 'Gintama°', 'Gintama.: Porori-hen']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX4JGeZMeH0Z"
      },
      "source": [
        "def animeCharacter(html_string):\n",
        "  personaggi=[]\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A= soup.find_all(class_=\"h3_characters_voice_actors\")    \n",
        "    for a in A:\n",
        "      personaggi.append(a.text)\n",
        "    return(personaggi)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzqCeBOgeJZt",
        "outputId": "59c6ff07-6425-4e26-bfea-756834e63bf5"
      },
      "source": [
        "animeCharacter('/content/drive/MyDrive/Anime_folderpage1/anime_11.html')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sakata, Gintoki',\n",
              " 'Kagura',\n",
              " 'Katsura, Kotarou',\n",
              " 'Takasugi, Shinsuke',\n",
              " 'Shimura, Shinpachi',\n",
              " 'Kamui',\n",
              " 'Elizabeth',\n",
              " 'Imai, Nobume',\n",
              " 'Sadaharu',\n",
              " 'Sakamoto, Tatsuma']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv0_M-g3eMBv"
      },
      "source": [
        "def animeVoices(html_string):\n",
        "  personaggi=[]\n",
        "  with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A= soup.find_all(class_=\"va-t ar pl4 pr4\")   \n",
        "    for a in A:\n",
        "      personaggi.append(a.text)\n",
        "\n",
        "      \n",
        "    return(personaggi)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqk2b5eyePYo",
        "outputId": "2bf910d2-cfb3-4f71-fdc8-c33e93e136a3"
      },
      "source": [
        "animeVoices('/content/drive/MyDrive/Anime_folderpage1/anime_11.html')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nSugita, Tomokazu\\nJapanese\\n',\n",
              " '\\nKugimiya, Rie\\nJapanese\\n',\n",
              " '\\nIshida, Akira\\nJapanese\\n',\n",
              " '\\nKoyasu, Takehito\\nJapanese\\n',\n",
              " '\\nSakaguchi, Daisuke\\nJapanese\\n',\n",
              " '\\nHino, Satoshi\\nJapanese\\n',\n",
              " '\\nHirano, Aya\\nJapanese\\n',\n",
              " '\\nTakahashi, Mikako\\nJapanese\\n',\n",
              " '\\nMiki, Shinichiro\\nJapanese\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WpR6mRueRqv"
      },
      "source": [
        "def createstaff(ll):\n",
        "    listto = []\n",
        "    for i in ll:\n",
        "        if i['href'].startswith('https://myanimelist.net/people/') and i['href'] not in listto:\n",
        "            if i.text != '\\n\\n':\n",
        "                j = str(i.text).replace('\\n', '')\n",
        "                j = re.sub(' +', ' ', j)\n",
        "            if j[0] == ' ':\n",
        "                j = j[1:]\n",
        "            if j[-1] == ' ':\n",
        "                j = j[:-1]\n",
        "            listto.append(j)\n",
        "    return listto      "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQhQfJLehBhf"
      },
      "source": [
        "def animeStaff(html_string):\n",
        "   with open(html_string, 'r') as f:\n",
        "    soup = BeautifulSoup(f, 'html.parser')\n",
        "    \n",
        "    A=  createstaff(soup.find_all('a', href=True))     \n",
        "    print(A)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWn7XsfveTfD",
        "outputId": "e48d1ba0-cfca-42b0-b003-faad0f81b201"
      },
      "source": [
        "animeStaff('/content/drive/MyDrive/Anime_folderpage1/anime_11.html')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sugita, Tomokazu', 'Sugita, Tomokazu', 'Kugimiya, Rie', 'Kugimiya, Rie', 'Ishida, Akira', 'Ishida, Akira', 'Koyasu, Takehito', 'Koyasu, Takehito', 'Sakaguchi, Daisuke', 'Sakaguchi, Daisuke', 'Hino, Satoshi', 'Hino, Satoshi', 'Hirano, Aya', 'Hirano, Aya', 'Takahashi, Mikako', 'Takahashi, Mikako', 'Miki, Shinichiro', 'Miki, Shinichiro', 'Miki, Shinichiro', 'Fujita, Youichi', 'Fujita, Youichi', 'Miyawaki, Chizuru', 'Miyawaki, Chizuru', 'Takamatsu, Shinji', 'Takamatsu, Shinji', 'Kobayashi, Katsuyoshi']\n"
          ]
        }
      ]
    }
  ]
}